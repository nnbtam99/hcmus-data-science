{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# BT01: Thu thập dữ liệu\n",
    "\n",
    "Họ tên: **Nguyễn Ngọc Băng Tâm**\n",
    "\n",
    "MSSV: **1712747**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Cách làm bài và nộp bài\n",
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân.\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "hoặc đối với những phần code không bắt buộc thì là:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "hoặc đối với markdown cell thì là:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một (hoặc một số) cell chứa các bộ test để giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng.\n",
    "\n",
    "Trong khi làm bài, bạn có thể cho in ra màn hình, tạo thêm các cell để test. Nhưng khi nộp bài thì bạn xóa các cell mà bạn tự tạo, xóa hoặc comment các câu lệnh in ra màn hình. Bạn lưu ý <font color=red>không được tự tiện xóa các cell hay sửa code của Thầy</font> (trừ những chỗ được phép sửa như đã nói ở trên).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>. Bạn có thể thảo luận ý tưởng với bạn khác, nhưng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font>. <font color=red>Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart Kernel & Run All Cells`, để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart Kernel & Run All Cells` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - Thư mục `BT01`\n",
    "        - File `BT01-ThuThapDuLieu.ipynb` (không cần nộp các file khác)\n",
    "\n",
    "Cuối cùng, bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. <font color=red>Bạn lưu ý tuân thủ chính xác cấu trúc này.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import requests\n",
    "import json\n",
    "import time # Dùng để sleep chương trình\n",
    "import pandas as pd # Dùng để đọc và hiển thị file csv (Pandas sẽ được học chi tiết ở buổi tới)\n",
    "import datetime as dt # Dùng để xử lý dữ liệu thời gian\n",
    "import re\n",
    "# YOUR CODE HERE (OPTION) \n",
    "# Nếu cần các thư viện khác thì bạn có thể import ở đây\n",
    "import urllib.robotparser # Kiểm tra file robot.txt có được phép crawl không"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## 1. Thu thập dữ liệu từ web bằng cách parse HTML (5đ)\n",
    "[Coursera](https://coursera.org) là trang cung cấp các khóa học online, là một nguồn tài liệu hữu ích để học tập. Trong phần này, bạn sẽ thu thập dữ liệu về các khóa học Data Science ở Coursera. \n",
    "\n",
    "Cụ thể là bạn sẽ viết hàm `collect_courses` ở bên dưới. Hàm này có các input như sau:\n",
    "- `course_urls_file`: là chuỗi, cho biết tên của file txt chứa các đường link đến các khóa học của Coursera (tất cả các khóa học, chứ không phải chỉ các khóa học về Data Science), mỗi đường link nằm trên một dòng; bạn sẽ đi theo đường link để lấy thông tin của khóa học. File này đã được cung cấp cho bạn: file \"course_urls.txt\" (mình tạo ra file này bằng cách parse [trang XML này](https://www.coursera.org/sitemap~www~courses.xml)). Theo file [robots.txt](https://www.coursera.org/robots.txt) thì các link trong file này đều được phép thu thập (bạn kiểm tra lại xem có đúng không). \n",
    "- `key_words`: là list, cho biết các từ khóa để lọc ra các link cần lấy. Ví dụ: `key_words=['data-science', 'datascience']` sẽ chỉ thu thập thông tin từ các link mà có từ \"data-science\" HOẶC \"datascience\" (chẳng hạn: https://www.coursera.org/learn/spatial-data-science).\n",
    "- `sleep_time`: là số thực, cho biết sau mỗi lần gửi request và parse lấy dữ liệu thì sẽ sleep bao nhiêu giây trước khi gửi tiếp lần request kế (sleep như vậy để tránh gửi quá nhiều request lên Coursera trong một thời gian ngắn). Trong hàm `collect_courses` bên dưới mình để giá trị mặc định là 1 giây. Trong Python, bạn sleep chương trình bằng câu lệnh `time.sleep(số giây)`.\n",
    "- `courses_file`: là chuỗi, cho biết tên của file csv dùng để lưu dữ liệu thu thập được; đây là file output (file này không có sẵn mà sẽ được tạo ra sau khi chạy hàm của bạn). Mình có cung cấp file output đúng \"correct_courses.csv\" (khi gọi hàm `collect_courses` với `key_words=['data-science', 'datascience']`) để bạn hình dung được nội dung cần có của file output. File này có các phần tử trên mỗi dòng được phân tách nhau bởi tab (`\\t`), và file này mã hóa utf-8. Bạn có thể xem file csv này ở JupyterLab bằng cách double-click vào file ở phía bên trái JupyterLab rồi chọn \"Delimiter\" là tab; hoặc xem ở dạng text bằng cách chuột phải vào file rồi \"Open With\", \"Editor\". File này gồm có các cột:\n",
    "    - `url`: đường link đến khóa học.\n",
    "    - `title`: tựa đề của khóa học.\n",
    "    - `provider`: trường cung cấp khóa học.\n",
    "    - `rating`: điểm số của khóa học (tại thời điểm bạn thu thập dữ liệu thì giá trị của cột này có thể sẽ hơi khác so với file output đúng của mình).\n",
    "    - `num_ratings`: số lượng người đã cho điểm cho khóa học (tại thời điểm bạn thu thập dữ liệu thì giá trị của cột này có thể sẽ hơi khác so với file output đúng của mình)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "925ed984709d1910bc53a87d128584ef",
     "grade": false,
     "grade_id": "cell-dc3850a3d53d80be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_courses(course_urls_file, key_words, courses_file, sleep_time=1):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "    rp.set_url('https://www.coursera.org/robots.txt')\n",
    "    rp.read()\n",
    "    \n",
    "    courses = []\n",
    "    \n",
    "    with open(course_urls_file, 'r') as inp:\n",
    "        for line in inp:\n",
    "            # Check robots.txt file\n",
    "            if rp.can_fetch('*', line):\n",
    "                 # Extract urls with key_words\n",
    "                result = [line for key_word in key_words if re.search(key_word, line)]\n",
    "                courses.extend(result)\n",
    "            else:\n",
    "                print(f\"Can't fetch {line}\")\n",
    "   \n",
    "    # Remove unnecessary characters in urls\n",
    "    urls = [course.replace('\\n', '') for course in courses]    \n",
    "\n",
    "    titles, providers, ratings, num_ratings = [], [], [], []\n",
    "    \n",
    "    session = HTMLSession()\n",
    "        \n",
    "    for url in urls:\n",
    "        # sleep before request a session \n",
    "        time.sleep(sleep_time)\n",
    "        r = session.get(url)\n",
    "        \n",
    "        if r.html.find('.banner-title', first=True) is not None:\n",
    "            title = r.html.find('.banner-title', first=True).text\n",
    "            \n",
    "            raw_provider = r.html.find('.rc-Partner__title')\n",
    "            \n",
    "            raw_provider = ([each_provider.text for each_provider in raw_provider])\n",
    "            provider = ' '.join(raw_provider)\n",
    "\n",
    "            XDPRating = r.html.find('.XDPRating', first=True)\n",
    "            \n",
    "            rating = XDPRating.find('.number-rating-expertise', first=True).text\n",
    "            rating = rating.replace('\\nstars', '')\n",
    "            num_rating = XDPRating.find('.ratings-count-expertise-style', first=True).text\n",
    "            num_rating = num_rating.replace('ratings', '')\n",
    "        else:\n",
    "            title = provider = rating = num_rating = ''\n",
    "\n",
    "        titles.append(title)\n",
    "        providers.append(provider)\n",
    "        ratings.append(rating)\n",
    "        num_ratings.append(num_rating)\n",
    "    \n",
    "#     # Create a DataFrame using 5 lists\n",
    "    courses_list = [urls, titles, providers, ratings, num_ratings]\n",
    "    df = pd.DataFrame(courses_list).transpose()\n",
    "    df.columns = ['url', 'title', 'provider', 'rating', 'num_ratings']       \n",
    "    df.to_csv(courses_file, sep='\\t', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ff72fc37c169d35422583361e59e377",
     "grade": true,
     "grade_id": "cell-f7ba8a08f45c6cf9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "collect_courses('course_urls.txt', ['data-science', 'datascience'], 'courses.csv')\n",
    "courses = pd.read_csv('courses.csv', sep='\\t')\n",
    "assert courses.shape == (26, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62a3bb1c02fe708c3dff8e41460d4c78",
     "grade": false,
     "grade_id": "cell-69bae8100b51ecac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>provider</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.coursera.org/learn/code-free-data-...</td>\n",
       "      <td>Code Free Data Science</td>\n",
       "      <td>University of California San Diego</td>\n",
       "      <td>4.4</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.coursera.org/learn/introduction-cl...</td>\n",
       "      <td>Introduction to Clinical Data Science</td>\n",
       "      <td>University of Colorado System</td>\n",
       "      <td>4.7</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.coursera.org/learn/what-is-datasci...</td>\n",
       "      <td>What is Data Science?</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.7</td>\n",
       "      <td>40,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.coursera.org/learn/the-data-scienc...</td>\n",
       "      <td>The Data Science of Health Informatics</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.coursera.org/learn/spatial-data-sc...</td>\n",
       "      <td>Spatial Data Science and Applications</td>\n",
       "      <td>Yonsei University</td>\n",
       "      <td>4.4</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.coursera.org/learn/data-science-me...</td>\n",
       "      <td>Data Science Methodology</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.6</td>\n",
       "      <td>14,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.coursera.org/learn/datasciencemath...</td>\n",
       "      <td>Data Science Math Skills</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.coursera.org/learn/sql-data-science</td>\n",
       "      <td>Databases and SQL for Data Science</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.7</td>\n",
       "      <td>12,132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.coursera.org/learn/data-science-fo...</td>\n",
       "      <td>Data Science for Business Innovation</td>\n",
       "      <td>EIT Digital Politecnico di Milano</td>\n",
       "      <td>4.2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.coursera.org/learn/python-for-data...</td>\n",
       "      <td>Python для анализа данных</td>\n",
       "      <td>Moscow Institute of Physics and Technology ФРО...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.coursera.org/learn/open-source-too...</td>\n",
       "      <td>Tools for Data Science</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.5</td>\n",
       "      <td>19,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.coursera.org/learn/data-science-k-...</td>\n",
       "      <td>Foundations of Data Science: K-Means Clusterin...</td>\n",
       "      <td>University of London Goldsmiths, University of...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.coursera.org/learn/executive-data-...</td>\n",
       "      <td>Executive Data Science Capstone</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1,385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.coursera.org/learn/competitive-dat...</td>\n",
       "      <td>How to Win a Data Science Competition: Learn f...</td>\n",
       "      <td>National Research University Higher School of ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.coursera.org/learn/advanced-data-s...</td>\n",
       "      <td>Advanced Data Science Capstone</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.6</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.coursera.org/learn/applied-data-sc...</td>\n",
       "      <td>Applied Data Science Capstone</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.coursera.org/learn/real-life-data-...</td>\n",
       "      <td>Data Science in Real Life</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2,086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.coursera.org/learn/data-science-et...</td>\n",
       "      <td>Data Science Ethics</td>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>4.7</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.coursera.org/learn/build-data-scie...</td>\n",
       "      <td>Building a Data Science Team</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.coursera.org/learn/intro-data-scie...</td>\n",
       "      <td>Introducción a Data Science: Programación Esta...</td>\n",
       "      <td>Universidad Nacional Autónoma de México</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://www.coursera.org/learn/python-for-appl...</td>\n",
       "      <td>Python for Data Science and AI</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4.6</td>\n",
       "      <td>18,991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://www.coursera.org/learn/data-science-pr...</td>\n",
       "      <td>Data Science Capstone</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1,086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.coursera.org/learn/sql-for-data-sc...</td>\n",
       "      <td>SQL for Data Science</td>\n",
       "      <td>University of California, Davis</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.coursera.org/learn/data-science-co...</td>\n",
       "      <td>A Crash Course in Data Science</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.coursera.org/learn/advanced-clinic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.coursera.org/learn/genomic-data-sc...</td>\n",
       "      <td>Genomic Data Science Capstone</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.6</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "0   https://www.coursera.org/learn/code-free-data-...   \n",
       "1   https://www.coursera.org/learn/introduction-cl...   \n",
       "2   https://www.coursera.org/learn/what-is-datasci...   \n",
       "3   https://www.coursera.org/learn/the-data-scienc...   \n",
       "4   https://www.coursera.org/learn/spatial-data-sc...   \n",
       "5   https://www.coursera.org/learn/data-science-me...   \n",
       "6   https://www.coursera.org/learn/datasciencemath...   \n",
       "7     https://www.coursera.org/learn/sql-data-science   \n",
       "8   https://www.coursera.org/learn/data-science-fo...   \n",
       "9   https://www.coursera.org/learn/python-for-data...   \n",
       "10  https://www.coursera.org/learn/open-source-too...   \n",
       "11  https://www.coursera.org/learn/data-science-k-...   \n",
       "12  https://www.coursera.org/learn/executive-data-...   \n",
       "13  https://www.coursera.org/learn/competitive-dat...   \n",
       "14  https://www.coursera.org/learn/advanced-data-s...   \n",
       "15  https://www.coursera.org/learn/applied-data-sc...   \n",
       "16  https://www.coursera.org/learn/real-life-data-...   \n",
       "17  https://www.coursera.org/learn/data-science-et...   \n",
       "18  https://www.coursera.org/learn/build-data-scie...   \n",
       "19  https://www.coursera.org/learn/intro-data-scie...   \n",
       "20  https://www.coursera.org/learn/python-for-appl...   \n",
       "21  https://www.coursera.org/learn/data-science-pr...   \n",
       "22  https://www.coursera.org/learn/sql-for-data-sc...   \n",
       "23  https://www.coursera.org/learn/data-science-co...   \n",
       "24  https://www.coursera.org/learn/advanced-clinic...   \n",
       "25  https://www.coursera.org/learn/genomic-data-sc...   \n",
       "\n",
       "                                                title  \\\n",
       "0                              Code Free Data Science   \n",
       "1               Introduction to Clinical Data Science   \n",
       "2                               What is Data Science?   \n",
       "3              The Data Science of Health Informatics   \n",
       "4               Spatial Data Science and Applications   \n",
       "5                            Data Science Methodology   \n",
       "6                            Data Science Math Skills   \n",
       "7                  Databases and SQL for Data Science   \n",
       "8                Data Science for Business Innovation   \n",
       "9                           Python для анализа данных   \n",
       "10                             Tools for Data Science   \n",
       "11  Foundations of Data Science: K-Means Clusterin...   \n",
       "12                    Executive Data Science Capstone   \n",
       "13  How to Win a Data Science Competition: Learn f...   \n",
       "14                     Advanced Data Science Capstone   \n",
       "15                      Applied Data Science Capstone   \n",
       "16                          Data Science in Real Life   \n",
       "17                                Data Science Ethics   \n",
       "18                       Building a Data Science Team   \n",
       "19  Introducción a Data Science: Programación Esta...   \n",
       "20                     Python for Data Science and AI   \n",
       "21                              Data Science Capstone   \n",
       "22                               SQL for Data Science   \n",
       "23                     A Crash Course in Data Science   \n",
       "24                                                NaN   \n",
       "25                      Genomic Data Science Capstone   \n",
       "\n",
       "                                             provider  rating num_ratings  \n",
       "0                  University of California San Diego     4.4         56   \n",
       "1                       University of Colorado System     4.7        246   \n",
       "2                                                 IBM     4.7     40,660   \n",
       "3                            Johns Hopkins University     4.7        117   \n",
       "4                                   Yonsei University     4.4        325   \n",
       "5                                                 IBM     4.6     14,989   \n",
       "6                                     Duke University     4.5      8,044   \n",
       "7                                                 IBM     4.7     12,132   \n",
       "8                   EIT Digital Politecnico di Milano     4.2         88   \n",
       "9   Moscow Institute of Physics and Technology ФРО...     4.5         85   \n",
       "10                                                IBM     4.5     19,625   \n",
       "11  University of London Goldsmiths, University of...     4.7        249   \n",
       "12                           Johns Hopkins University     4.7      1,385   \n",
       "13  National Research University Higher School of ...     4.7        996   \n",
       "14                                                IBM     4.6        332   \n",
       "15                                                IBM     4.7      4,828   \n",
       "16                           Johns Hopkins University     4.4      2,086   \n",
       "17                             University of Michigan     4.7        486   \n",
       "18                           Johns Hopkins University     4.5      2,989   \n",
       "19            Universidad Nacional Autónoma de México     4.7      6,085   \n",
       "20                                                IBM     4.6     18,991   \n",
       "21                           Johns Hopkins University     4.5      1,086   \n",
       "22                    University of California, Davis     4.6      7,479   \n",
       "23                           Johns Hopkins University     4.5      6,916   \n",
       "24                                                NaN     NaN         NaN  \n",
       "25                           Johns Hopkins University     4.6         48   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "---\n",
    "## 2. Thu thập dữ liệu từ web bằng cách dùng web API (5đ)\n",
    "Trong phần này, bạn sẽ dùng GitHub API để thu thập các thùng chứa về Data Science. Để đơn giản, bạn sẽ dùng API không chứng thực (không cần đăng ký tài khoản, không cần key) của GitHub. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 2.1. Thu thập ít hơn hoặc bằng 1000 thùng chứa (2.5đ)\n",
    "Đầu tiên, bạn sẽ viết hàm `collect_repositories` ở bên dưới. Hàm này có các input:\n",
    "- `start_date` và `end_date`: là chuỗi, cho biết là muốn tìm các thùng chứa được tạo từ ngày nào đến ngày nào (bao gồm cả 2 đầu). Ví dụ, `start_date='2017-01-01'` (năm-tháng-ngày) và `end_date='2017-01-31'`.\n",
    "- `keyword`: là chuỗi, cho biết là muốn tìm kiếm các thùng chứa với từ khóa nào (xuất hiện ở tên thùng chứa hoặc phần mô tả của thùng chứa). Ví dụ, `keyword='data science'`.\n",
    "- `per_page`: là số nguyên, cho biết là muốn bao nhiêu kết quả trên một page. Hiện giờ GitHub cho tối đa là `per_page=100`.\n",
    "\n",
    "Trong hàm này bạn sẽ vào đường link `f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}&per_page={per_page}'` (dạng f-string trong Python) để thu thập dữ liệu. Ví dụ, bạn có thể vào thử ở web browser: https://api.github.com/search/repositories?q=data%20science%20created:2017-01-01..2017-01-31&per_page=100 (khi nhập một đường link vào web browser và enter thì một số ký tự sẽ bị mã hóa; ví dụ khoảng trắng sẽ bị mã hóa là %20 hoặc +), hoặc dùng thư viện Requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Thư viện requests sẽ tự động mã hóa khoảng trắng cho bạn\n",
    "# Bạn có thể xem đường link sau khi đã mã hóa bằng câu lệnh: r.url\n",
    "r = requests.get('https://api.github.com/search/repositories?q=data science created:2017-01-01..2017-01-31&per_page=100&page=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"total_count\":1570,\"incomplete_results\":false,\"items\":[{\"id\":79030157,\"node_id\":\"MDEwOlJlcG9zaXRvcn\n"
     ]
    }
   ],
   "source": [
    "# Xem 100 ký tự đầu tiên trong chuỗi JSON lấy được\n",
    "print(r.text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Bạn thấy \"total_count\" có giá trị là 1615, nghĩa là tìm được 1615 thùng chứa. Tuy nhiên, đây chỉ là trang đầu tiên và chỉ có 100 thùng chứa (số lượng phần tử của \"items\"). Link tới trang kế tiếp nằm trong headers của nội dung gửi về từ server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<https://api.github.com/search/repositories?q=data+science+created%3A2017-01-01..2017-01-31&per_page=100&page=2>; rel=\"next\", <https://api.github.com/search/repositories?q=data+science+created%3A2017-01-01..2017-01-31&per_page=100&page=10>; rel=\"last\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['Link']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Link tới trang kế tiếp là link mà ở bên cạnh phía phải có từ `rel=\"next\"`. `rel=\"last\"` nghĩa là trang cuối. Vì đây là trang đầu tiên nên chỉ có \"next\" và \"last\", trang ở giữa còn có thêm \"first\" (trang đầu) và \"prev\" (trang trước). Bạn có thể xem thêm ở [document](https://developer.github.com/v3/guides/traversing-with-pagination/).\n",
    "\n",
    "Nếu để ý thì bạn thấy trang cuối là `page=10`, nghĩa là tất cả các trang chỉ có $10\\times100=1000$ thùng chứa. Trong khi đó, \"total_count\" là 1615. Lý do: \"the GitHub Search API provides up to **1,000 results for each search**\" ([document](https://developer.github.com/v3/search/)). Trong hàm này chỉ yêu cầu bạn lấy hết kết quả ở tất cả các trang là được ($\\le1000$ kết quả). Việc lấy $>1000$ kết quả sẽ làm ở phần kế tiếp.\n",
    "\n",
    "Một yêu cầu nữa trong hàm này là khi hết số lượng request được phép trong 1 phút (với API không chứng thực thì hiện nay được 10 request / phút) thì bạn phải cho chương trình đợi cho đến khi được reset lại (thường thì không cần đợi tới 1 phút vì thời gian 1 phút là tính từ lần request đầu tiên). Cách làm là bạn sẽ cho chương trình sleep 1 giây rồi dậy xem được reset chưa, nếu chưa thì lại sleep 1 giây rồi dậy ... Bạn lưu ý là, <font color=red>không được giả định lần request đầu tiên là chắc chắn thành công</font> (vì khi chấm bài mình sẽ phải chạy nhiều bài và có thể đến bài của bạn đã hết lượt request được phép). Để xem số lượng request còn lại, bạn có thể xem header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['X-RateLimit-Remaining'] # Lưu ý kết quả trả về là chuỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Khi số lượng request còn lại bằng 0 thì có 2 trường hợp có thể xảy ra:\n",
    "- Lần request vừa xong thành công (là lần request cuối cùng được phép), lúc này `r.ok` bằng `True`.\n",
    "- Lần request vừa xong không thành công (đã hết lượng request được phép), lúc này `r.ok` bằng `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Output trả về của hàm `collect_repositories`:\n",
    "- `repositories`: là list các thùng chứa lấy được (list gồm \"item\" của tất cả các trang)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20cb81a6aca154078aed4053c325d8ec",
     "grade": false,
     "grade_id": "cell-62a49f8fda9cd909",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_repositories(start_date, end_date, keyword='data science', per_page=100):\n",
    "    repositories = []\n",
    "    # YOUR CODE HERE\n",
    "    page = 1  \n",
    "    \n",
    "    # the last page is always page 10\n",
    "    while page <= 10:\n",
    "        url = f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}&per_page={per_page}&page={page}'\n",
    "        r = requests.get(url)\n",
    "            \n",
    "        if r.ok == True:\n",
    "            json_pydata = r.json()\n",
    "            if len(json_pydata['items']) == 0: # no items left on that page\n",
    "                break\n",
    "            repositories.extend(json_pydata['items'])    \n",
    "    \n",
    "            page += 1\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "            \n",
    "    \n",
    "    return repositories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e6f450a5a2bafe89fda0fa4edc6d3b8",
     "grade": true,
     "grade_id": "cell-f9dd722733b1a0b8",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-01-15'\n",
    "keyword = 'data science'\n",
    "per_page = 100\n",
    "repositories = collect_repositories(start_date, end_date, keyword, per_page)\n",
    "print(len(repositories))\n",
    "\n",
    "url = f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}'\n",
    "finish = False\n",
    "while finish == False:\n",
    "    r = requests.get(url)\n",
    "    if r.ok == True:\n",
    "        json_pydata = r.json()\n",
    "        if json_pydata['incomplete_results'] == False: \n",
    "            total_count = json_pydata['total_count']\n",
    "            finish = True\n",
    "    else:\n",
    "        time.sleep(1)\n",
    "assert len(repositories) == total_count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 2.2. Thu thập nhiều hơn 1000 thùng chứa (2.5đ)\n",
    "Để thu thập hết 1615 thùng chứa trong ví dụ ở trên, ta sẽ: \n",
    "- Chia khoảng thời gian các thùng chứa được tạo mà ta cần tìm kiếm ra các khoảng thời gian nhỏ hơn. Ví dụ chia 2017-01-01..2017-01-15 thành 2017-01-01..2017-01-07, 2017-01-08..2017-01-14, 2017-01-15..2017-01-15; ở đây, mỗi khoảng thời gian nhỏ gồm 7 ngày (kể cả 2 đầu), khoảng thời gian nhỏ sau cùng có thể sẽ không đủ 7 ngày (do bị lẻ). Trong Python, để làm việc với dữ liệu thời gian, bạn có thể dùng thư viện `datetime`; bạn có thể tự tìm hiểu về thư viện này ở: [document](https://docs.python.org/3.7/library/datetime.html), [Corey's video](https://www.youtube.com/watch?v=eirjjyP2qcQ), Google.\n",
    "- Tìm kiếm với khoảng thời gian nhỏ hơn này bằng hàm `collect_repositories` ở trên (với khoảng thời gian đủ nhỏ sẽ có $\\le1000$ thùng chứa).\n",
    "- Kết hợp kết quả từ các lần tìm kiếm với các khoảng thời gian nhỏ này lại.\n",
    "\n",
    "Bạn sẽ cài đặt các bước này ở hàm `collect_all_repositories` dưới đây. Hàm này có các input:\n",
    "- `start_date`, `end_date`, `keyword`, `per_page`: các input này giống như ở hàm `collect_repositories`.\n",
    "- `step`: là số nguyên, cho biết khoảng thời gian nhỏ gồm bao nhiêu ngày (tính cả 2 đầu). Trong ví dụ ở trên, `step=7`.\n",
    "\n",
    "Output trả về của hàm này:\n",
    "- `all_repositories`: là list tất cả các thùng chứa (\"item\") lấy được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e58dcaf52d67ca4b5a41299b636282ab",
     "grade": false,
     "grade_id": "cell-186ad6493e39e40c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_all_repositories(start_date, end_date, step, keyword='data science', per_page=100):\n",
    "    all_repositories = []\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Create (start_date, end_date) intervals\n",
    "    date_intervals = [] \n",
    "    \n",
    "    # Calculate the time difference when binning the date\n",
    "    dt_end_date = dt.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    dt_start_date = dt.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    time_left = dt_end_date - dt_start_date\n",
    "  \n",
    "    while (time_left.days > step): \n",
    "        dt_next_date = dt_start_date + dt.timedelta(days=step - 1)\n",
    "        next_date = dt.datetime.strftime(dt_next_date, \"%Y-%m-%d\")\n",
    "        start_date = dt.datetime.strftime(dt_start_date, \"%Y-%m-%d\")\n",
    "        date_intervals.append((start_date, next_date))\n",
    "        \n",
    "        time_left = dt_end_date - dt_next_date\n",
    "        dt_start_date = dt_next_date + dt.timedelta(days=1)\n",
    "        \n",
    "    # Handle the remaining days\n",
    "    start_date = dt.datetime.strftime(dt_start_date, \"%Y-%m-%d\")\n",
    "    dt_next_date = dt_start_date + dt.timedelta(days=time_left.days - 1)\n",
    "    next_date = dt.datetime.strftime(dt_next_date, \"%Y-%m-%d\")\n",
    "    date_intervals.append((start_date, next_date))\n",
    "        \n",
    "    page = 1\n",
    "    \n",
    "    for start_date, end_date in date_intervals:\n",
    "        while page <= 10:\n",
    "            url = f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}&per_page={per_page}&page={page}'\n",
    "            r = requests.get(url)\n",
    "\n",
    "            if r.ok == True:\n",
    "                json_pydata = r.json()\n",
    "                if len(json_pydata['items']) == 0: # no items left on that page\n",
    "                    page = 1\n",
    "                    break\n",
    "                \n",
    "                all_repositories.extend(json_pydata['items'])    \n",
    "\n",
    "                page += 1\n",
    "    \n",
    "            else:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    return all_repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e10538857f0a28d84ee3ae2e659cbcc5",
     "grade": true,
     "grade_id": "cell-eb93b1b4dd11e993",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-01-31'\n",
    "step = 10\n",
    "keyword = 'data science'\n",
    "per_page = 100\n",
    "all_repositories = collect_all_repositories(start_date, end_date, step, keyword, per_page)\n",
    "print(len(all_repositories))\n",
    "\n",
    "url = f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}'\n",
    "finish = False\n",
    "while finish == False:\n",
    "    r = requests.get(url)\n",
    "    if r.ok == True:\n",
    "        json_pydata = r.json()\n",
    "        if json_pydata['incomplete_results'] == False: \n",
    "            total_count = json_pydata['total_count']\n",
    "            finish = True\n",
    "    else:\n",
    "        time.sleep(1)\n",
    "assert len(all_repositories) == total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
